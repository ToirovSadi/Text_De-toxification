{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad2118f3-61a9-4655-bde9-b26e97cc7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL = 'models/transformer2.01.pt'\n",
    "MODEL_CHECKPOINT = 'models/transformer2.01.pt'\n",
    "DATASET_PATH = 'data/interim/preprocessed_paranmt3.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40068414-5b9f-4586-bcdb-470c3efb7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\") # go to the root dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd8b060-2108-4d18-865c-f9de2ae7969c",
   "metadata": {},
   "source": [
    "## Get the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c079f37c-1954-4a89-b159-84b750279697",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_SIZE = 32\n",
    "MAX_TOKENS = 25_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26e343f-e42b-442e-9bb4-0a0d96bbf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import ParanmtDataset\n",
    "\n",
    "train_dataset = ParanmtDataset(\n",
    "    path=DATASET_PATH,\n",
    "    max_sent_size=MAX_SENT_SIZE,\n",
    "    train=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3545056a-cc41-46b1-8246-1b7516cb8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.build_vocab(\n",
    "    min_freq=2,\n",
    "    specials=['<unk>', '<pad>', '<sos>', '<eos>'],\n",
    "    max_tokens=MAX_TOKENS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67722bfa-d4d6-499a-9862-d7e9ca0ad165",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_vocab = train_dataset.toxic_vocab\n",
    "dec_vocab = train_dataset.neutral_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e4b03a-911c-4999-8372-2e2cdfda5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of encoder vocab: 25000\n",
      "size of decoder vocab: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"size of encoder vocab:\", len(enc_vocab))\n",
    "print(\"size of decoder vocab:\", len(dec_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40e15519-eb8f-4164-82a4-6fe43237e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = ParanmtDataset(\n",
    "    path=DATASET_PATH,\n",
    "    max_sent_size=MAX_SENT_SIZE,\n",
    "    vocabs=(enc_vocab, dec_vocab), # avoid data leakage\n",
    "    train=False,\n",
    "    seed=42,\n",
    "    take_first=10_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e54778-c844-4370-9329-93a26270d0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(499273, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa20304-6d4f-457e-bb38-518308c38543",
   "metadata": {},
   "source": [
    "## Let's create Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec52e669-ab26-42a5-a192-e0b7d46cb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52e6306f-5a09-4ae1-a202-208fea6562bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e60c1f04-f350-4f9b-8960-1cca38e70a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_sent.shape: torch.Size([256, 32])\n",
      "neutral_sent.shape: torch.Size([256, 32])\n"
     ]
    }
   ],
   "source": [
    "# let's check if shape and everything is ok\n",
    "for batch in train_dataloader:\n",
    "    toxic_sent, neutral_sent = batch\n",
    "    print(\"toxic_sent.shape:\", toxic_sent.shape)\n",
    "    print(\"neutral_sent.shape:\", neutral_sent.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dca808e2-529f-4c8e-b035-3b03ec7d053d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46dfbe-d834-48e7-ad09-c49c2a676386",
   "metadata": {},
   "source": [
    "# Load the Model\n",
    "\n",
    "- Transformer architerture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c1113a1-d18c-43f3-94b1-1d44f02ac03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.transformer.encoder import Encoder\n",
    "from src.models.transformer.decoder import Decoder\n",
    "from src.models.transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451a159a-dae5-487c-be50-c87b7407add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure some parameters for the model\n",
    "heads = 4\n",
    "hidden_dim = 256\n",
    "ff_expantion = 4\n",
    "max_size = MAX_SENT_SIZE\n",
    "\n",
    "## Encoder\n",
    "enc_input_dim = len(enc_vocab)\n",
    "enc_dropout = 0.1\n",
    "enc_num_layers = 3\n",
    "enc_padding_idx = enc_vocab['<pad>']\n",
    "\n",
    "## Decoder\n",
    "dec_output_dim = len(dec_vocab)\n",
    "dec_dropout = 0.1\n",
    "dec_num_layers = 3\n",
    "dec_padding_idx = dec_vocab['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b48dfdf-ba48-477c-ac62-2c512a69d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# load the encoder and decoder for our model\n",
    "encoder = Encoder(\n",
    "    input_dim=enc_input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=enc_num_layers,\n",
    "    heads=heads,\n",
    "    ff_expantion=ff_expantion,\n",
    "    dropout=enc_dropout,\n",
    "    device=device,\n",
    "    max_size=max_size,\n",
    "    vocab=enc_vocab,\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim=dec_output_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=dec_num_layers,\n",
    "    heads=heads,\n",
    "    ff_expantion=ff_expantion,\n",
    "    dropout=dec_dropout,\n",
    "    device=device,\n",
    "    max_size=max_size,\n",
    "    vocab=dec_vocab,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb68fa7c-f8ee-4667-9b20-a638de4fe311",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = float('inf')\n",
    "\n",
    "model = Transformer(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    device=device,\n",
    "    max_sent_size=MAX_SENT_SIZE,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088f446e-d95e-4812-949d-a3a5eb20ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=decoder.padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae355174-b99f-403c-b926-def9bd694c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training 1: 100%|██████████| 1951/1951 [04:33<00:00,  7.14it/s, loss=4.9] \n",
      "Evaluating 1: 100%|██████████| 40/40 [00:02<00:00, 18.86it/s, loss=4.03]\n",
      "Training 2: 100%|██████████| 1951/1951 [04:30<00:00,  7.21it/s, loss=3.96]\n",
      "Evaluating 2: 100%|██████████| 40/40 [00:02<00:00, 19.01it/s, loss=3.68]\n",
      "Training 3: 100%|██████████| 1951/1951 [04:31<00:00,  7.19it/s, loss=3.69]\n",
      "Evaluating 3: 100%|██████████| 40/40 [00:02<00:00, 19.30it/s, loss=3.46]\n",
      "Training 4: 100%|██████████| 1951/1951 [04:33<00:00,  7.14it/s, loss=3.51]\n",
      "Evaluating 4: 100%|██████████| 40/40 [00:02<00:00, 18.74it/s, loss=3.29]\n",
      "Training 5: 100%|██████████| 1951/1951 [04:30<00:00,  7.20it/s, loss=3.37]\n",
      "Evaluating 5: 100%|██████████| 40/40 [00:02<00:00, 18.40it/s, loss=3.18]\n",
      "Training 6: 100%|██████████| 1951/1951 [04:31<00:00,  7.18it/s, loss=3.26]\n",
      "Evaluating 6: 100%|██████████| 40/40 [00:02<00:00, 18.56it/s, loss=3.07]\n",
      "Training 7: 100%|██████████| 1951/1951 [04:31<00:00,  7.19it/s, loss=3.16]\n",
      "Evaluating 7: 100%|██████████| 40/40 [00:02<00:00, 18.55it/s, loss=2.99]\n",
      "Training 8: 100%|██████████| 1951/1951 [04:32<00:00,  7.16it/s, loss=3.08]\n",
      "Evaluating 8: 100%|██████████| 40/40 [00:02<00:00, 19.30it/s, loss=2.91]\n",
      "Training 9: 100%|██████████| 1951/1951 [04:32<00:00,  7.17it/s, loss=3.01]\n",
      "Evaluating 9: 100%|██████████| 40/40 [00:02<00:00, 19.23it/s, loss=2.84]\n",
      "Training 10: 100%|██████████| 1951/1951 [04:31<00:00,  7.19it/s, loss=2.94]\n",
      "Evaluating 10: 100%|██████████| 40/40 [00:02<00:00, 19.18it/s, loss=2.78]\n"
     ]
    }
   ],
   "source": [
    "from src.models.train_model import train\n",
    "\n",
    "best_loss = train(\n",
    "    model=model,\n",
    "    loaders=(train_dataloader, val_dataloader),\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    epochs=10,\n",
    "    device=device,\n",
    "    best_loss=best_loss,\n",
    "    ckpt_path=MODEL_CHECKPOINT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dc1b6ad-901d-4582-84c8-79ba34fdcebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the model and predict\n",
    "model = torch.load(MODEL_CHECKPOINT)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3f96417-66e1-4061-ba49-55207e953142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic_sent: see her die a thousand ways.\n",
      "neutral_sent: and seeing her die in thousands of ways.\n",
      "prediction: see her death.\n",
      "\n",
      "\n",
      "toxic_sent: with explosives around my ankles, ready to explode.\n",
      "neutral_sent: explosives still around their ankles, still ready to explode.\n",
      "prediction: with my, ready to explode.\n",
      "\n",
      "\n",
      "toxic_sent: fucked up my life.\n",
      "neutral_sent: he messed up his life.\n",
      "prediction: i screwed up my life.\n",
      "\n",
      "\n",
      "toxic_sent: and he is the son of death.\n",
      "neutral_sent: he is a dead man.\n",
      "prediction: and he is the son of death.\n",
      "\n",
      "\n",
      "toxic_sent: they said if i told anyone, they would kill zak.\n",
      "neutral_sent: they said that if we told anybody that they said they would hurt zach.\n",
      "prediction: they said if i told anyone, they would have killed.\n",
      "\n",
      "\n",
      "toxic_sent: but now you are completely crazy.\n",
      "neutral_sent: now i know you are completely mad.\n",
      "prediction: but now you are completely mad.\n",
      "\n",
      "\n",
      "toxic_sent: his alibi is bullshit.\n",
      "neutral_sent: his alibi is bogus.\n",
      "prediction: his is nonsense.\n",
      "\n",
      "\n",
      "toxic_sent: damn i i should have gone over and told her we were back.\n",
      "neutral_sent: i should have gone, tell her we came back.\n",
      "prediction: i should have gone, and we told her.\n",
      "\n",
      "\n",
      "toxic_sent: we are talking about a drug dealer and maybe a cop killer.\n",
      "neutral_sent: we are talking about a drug dealer here and possible cop killer.\n",
      "prediction: we are talking about a drug dealer and maybe a cop.\n",
      "\n",
      "\n",
      "toxic_sent: black is a blind remembering, she thought.\n",
      "neutral_sent: the worm is a blind memory, she thought.\n",
      "prediction: black is a blind, she thought.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "detokenizer = TreebankWordDetokenizer()\n",
    "\n",
    "# let's see how our model works\n",
    "num_examples = 10\n",
    "df = val_dataset\n",
    "for _ in range(num_examples):\n",
    "    idx = np.random.randint(0, len(df))\n",
    "    toxic_sent = detokenizer.detokenize(df.df.loc[idx, 'toxic_sent'])\n",
    "    neutral_sent = detokenizer.detokenize(df.df.loc[idx, 'neutral_sent'])\n",
    "\n",
    "    print('toxic_sent:', toxic_sent)\n",
    "    print('neutral_sent:', neutral_sent)\n",
    "    print('prediction:', model.predict(toxic_sent, post_process_text=True, use_beam_search=True)[0])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a64a1c19-80aa-40fc-bf7d-6b55d819fbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_bleu(dataset, model):\n",
    "    preds = []\n",
    "    trgs = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            toxic_sent, neutral_sent = dataset[i]\n",
    "            toxic_sent = toxic_sent.to(model.device).unsqueeze(0)\n",
    "            pred = model.predict(toxic_sent, post_process_text=False)\n",
    "            \n",
    "            pred = pred[1:-1] # remove <sos> and <eos>\n",
    "            \n",
    "            neutral_sent = model.decoder.vocab.lookup_tokens(neutral_sent.numpy())\n",
    "            neutral_sent = neutral_sent[1:] # remove <sos>\n",
    "            neutral_sent = neutral_sent[:neutral_sent.index('<eos>')]\n",
    "            \n",
    "            preds.append(pred)\n",
    "            trgs.append([neutral_sent])\n",
    "        \n",
    "    return bleu_score(preds, trgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "518068d1-2d67-4c58-8e33-f577b0a53cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:58<00:00, 33.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19219723264416075"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu(val_dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e41c9e-be99-4275-bee1-ebc699428aea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
